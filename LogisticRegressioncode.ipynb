{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch the 20 newsgroups dataset\n",
    "# newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Partiall dataset\n",
    "# categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "\n",
    "# Fetch the \"train\" subset of the data to be used\n",
    "# newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Vectorizing the text from the given dataset using TF-IDF to get the matrix\n",
    "data_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = data_vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "# Defining the k-fold cross-validation with 5 folds measures to obtain the 5 groups\n",
    "kFold = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "# Defining logistic regression model with 1000 interations\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Defining place holder lists for the metrics for each of the resulting folds\n",
    "accuracies_array = []\n",
    "precisions_array = []\n",
    "recalls_array = []\n",
    "# Implementing k-fold cross-validation using the test and train data\n",
    "for train_position, test_position in kFold.split(X_tfidf, newsgroups.target):\n",
    "    X_trainData= X_tfidf[train_position]\n",
    "    X_testData = X_tfidf[test_position]\n",
    "    y_trainData = newsgroups.target[train_position]\n",
    "    y_testData= newsgroups.target[test_position]\n",
    "\n",
    "    \n",
    "    #Using the training portion of data to train it for our Logistic regression model\n",
    "    logistic_regression.fit(X_trainData, y_trainData)\n",
    "\n",
    "    # Defining our predicts on the test data of the dataset\n",
    "    y_predictData = logistic_regression.predict(X_testData)\n",
    "\n",
    "    # Analysing the models using each of the k-folds\n",
    "    accuracy = accuracy_score(y_testData, y_predictData)\n",
    "    classification_report_dict = classification_report(y_testData, y_predictData, output_dict=True)\n",
    "    \n",
    "    \n",
    "    # Adding the metrictics int the defined lists to be used for final average\n",
    "    accuracies_array.append(accuracy)\n",
    "    precisions_array.append(classification_report_dict['macro avg']['precision'])\n",
    "    recalls_array.append(classification_report_dict['macro avg']['recall'])\n",
    "\n",
    "    # Dispaying the results of the metrics of the 5 folds\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(classification_report(y_testData, y_predictData))\n",
    "\n",
    "# Aggregate and displays the average rsults of the metrics using all the k-folds.\n",
    "avg_accuracy = sum(accuracies_array) / len(accuracies_array)\n",
    "avg_precision = sum(precisions_array) / len(precisions_array)\n",
    "avg_recall = sum(recalls_array) / len(recalls_array)\n",
    "\n",
    "# Final display of the results\n",
    "print(\"\\nAverage Metrics Across the 5 K-Folds:\")\n",
    "print(f'Average Accuracy of the dataset is: {avg_accuracy:.2f}')\n",
    "print(f'Average Precision of the dataset is: {avg_precision:.2f}')\n",
    "print(f'Average Recall of the dataset is: {avg_recall:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Part2\n",
    "\n",
    "\n",
    "def read_train_imdb():\n",
    "    directory = 'data/train/neg'\n",
    "    data = []\n",
    "    labels = []\n",
    "    file = ''\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"neg\"\n",
    "            for i in f:\n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                    \n",
    "                data.append(i)\n",
    "                labels.append(0)\n",
    "                     \n",
    "        directory = 'data1/train/pos'\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"pos\"\n",
    "            for i in f:\n",
    "             \n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                     \n",
    "                data.append(i)\n",
    "                labels.append(1)\n",
    "                \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Error found in file:\", file)\n",
    "        \n",
    "    npdata = np.array(data)\n",
    "    nplabels = np.array(labels)\n",
    "    \n",
    "    return npdata, nplabels\n",
    "  \n",
    "train_data, train_labels = read_train_imdb()\n",
    "\n",
    "def read_test_imdb():\n",
    "    directory = 'data/test/neg'\n",
    "    data = []\n",
    "    labels = []\n",
    "    file = ''\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"neg\"\n",
    "            for i in f:\n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                    \n",
    "                data.append(i)\n",
    "                labels.append(0)\n",
    "                \n",
    "        \n",
    "        directory = 'data/test/pos'\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"pos\"\n",
    "            for i in f:\n",
    "             \n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                     \n",
    "                data.append(i)\n",
    "                labels.append(1)\n",
    "                \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Error found in file:\", file)\n",
    "    \n",
    "    npdata = np.array(data)\n",
    "    nplabels = np.array(labels)\n",
    "    \n",
    "    return npdata, nplabels\n",
    "  \n",
    "test_data, test_labels = read_test_imdb()\n",
    "\n",
    "# Vectorizing the text from the given dataset using TF-IDF to get the matrix\n",
    "# data_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "data_vectorizer = TfidfVectorizer(analyzer = 'word',max_features=10000)\n",
    "X_tfidf = data_vectorizer.fit_transform(train_data)\n",
    "\n",
    "# Defining the k-fold cross-validation with 5 folds measures to obtain the 5 groups\n",
    "kFold = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "# Defining logistic regression model with 1000 interations\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Defining place holder lists for the metrics for each of the resulting folds\n",
    "accuracies_array = []\n",
    "precisions_array = []\n",
    "recalls_array = []\n",
    "\n",
    "# # Implementing k-fold cross-validation using the test and train data\n",
    "for train_position, test_position in kFold.split(X_tfidf, train_labels):\n",
    "    X_trainData = X_tfidf[train_position]\n",
    "    X_testData = X_tfidf[test_position]\n",
    "    y_trainData = train_labels[train_position]\n",
    "    y_testData = train_labels[test_position]\n",
    "\n",
    "\n",
    "    \n",
    "    #Using the training portion of data to train it for our Logistic regression model\n",
    "    logistic_regression.fit(X_trainData, y_trainData)\n",
    "\n",
    "    # Defining our predicts on the test data of the dataset\n",
    "    y_predictData = logistic_regression.predict(X_testData)\n",
    "\n",
    "    # Analysing the models using each of the k-folds\n",
    "    accuracy = accuracy_score(y_testData, y_predictData)\n",
    "    classification_report_dict = classification_report(y_testData, y_predictData, output_dict=True)\n",
    "    \n",
    "    \n",
    "    # Adding the metrictics int the defined lists to be used for final average\n",
    "    accuracies_array.append(accuracy)\n",
    "    precisions_array.append(classification_report_dict['macro avg']['precision'])\n",
    "    recalls_array.append(classification_report_dict['macro avg']['recall'])\n",
    "\n",
    "    # Dispaying the results of the metrics of the 5 folds\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(classification_report(y_testData, y_predictData))\n",
    "\n",
    "# Aggregate and displays the average rsults of the metrics using all the k-folds.\n",
    "avg_accuracy = sum(accuracies_array) / len(accuracies_array)\n",
    "avg_precision = sum(precisions_array) / len(precisions_array)\n",
    "avg_recall = sum(recalls_array) / len(recalls_array)\n",
    "\n",
    "# Final display of the results\n",
    "print(\"\\nAverage Metrics Across the 5 K-Folds:\")\n",
    "print(f'Average Accuracy of the dataset is: {avg_accuracy:.2f}')\n",
    "print(f'Average Precision of the dataset is: {avg_precision:.2f}')\n",
    "print(f'Average Recall of the dataset is: {avg_recall:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
