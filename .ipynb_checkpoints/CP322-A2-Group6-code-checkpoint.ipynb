{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbf00d2",
   "metadata": {},
   "source": [
    "# <div align=\"center\">CP322-A Mini-Project 2: Machine Learning</div>\n",
    "## <div align=\"center\">Group 6</div>\n",
    "### <div align=\"center\">due on 12-Nov-2023 at 11:30 PM</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52edb19",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f51c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831ebc8",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10493e",
   "metadata": {},
   "source": [
    "### Dataset 1 (20 Newsgroup): \n",
    "\n",
    "Use the default train subset (subset=‘train’, and remove=([‘headers’, ‘footers’, ‘quotes’]) in  sklearn.datasets) to train the models and report the final performance on the test subset.  note: you need to start with the text data and convert the text to feature vectors. Please refer to https://scikitlearn.org/stable/tutorial/text_analytics/working_with_text_data.html for a tutorial on the steps needed for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c95110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "filename = \"data/IMDB.gz\"\n",
    "\n",
    "downsampling_factor = 10\n",
    "\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data = f.read().decode('utf-8')\n",
    "\n",
    "lines = data.splitlines()\n",
    "max_columns = 0  # Initialize a variable to track the maximum number of columns in any row\n",
    "\n",
    "# Iterate through the lines and determine the maximum number of columns\n",
    "for i, line in enumerate(lines):\n",
    "    if i % downsampling_factor == 0:\n",
    "        row = line.split(',')\n",
    "        max_columns = max(max_columns, len(row))\n",
    "\n",
    "# Initialize a list to store the downsampled and padded rows\n",
    "downsampled_data_list = []\n",
    "\n",
    "# Iterate through the lines again, splitting and padding the rows\n",
    "for i, line in enumerate(lines):\n",
    "    if i % downsampling_factor == 0:\n",
    "        row = line.split(',')\n",
    "        # Pad with zeros if the row has fewer columns than the maximum\n",
    "        while len(row) < max_columns:\n",
    "            row.append('0')  # You can change '0' to another value if needed\n",
    "        downsampled_data_list.append(row)\n",
    "\n",
    "# Convert the padded data list to a NumPy array\n",
    "\n",
    "# print(downsampled_data_list)\n",
    "# numpy_array = np.array(downsampled_data_list, dtype=float)\n",
    "\n",
    "# print(numpy_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51515f",
   "metadata": {},
   "source": [
    "### Dataset 2 (IMDB Reviews):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6926886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b18c4fa",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109455e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f503d818",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0190c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a89a8ad7",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba31ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b679695c",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4911e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eeb7795",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85c72f9",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7283a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
