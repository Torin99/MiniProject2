{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbf00d2",
   "metadata": {},
   "source": [
    "# <div align=\"center\">CP322-A Mini-Project 2: Machine Learning</div>\n",
    "## <div align=\"center\">Group 6</div>\n",
    "### <div align=\"center\">due on 12-Nov-2023 at 11:30 PM</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52edb19",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18f51c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831ebc8",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10493e",
   "metadata": {},
   "source": [
    "### Dataset 1 (20 Newsgroup): \n",
    "\n",
    "Use the default train subset (subset=‘train’, and remove=([‘headers’, ‘footers’, ‘quotes’]) in  sklearn.datasets) to train the models and report the final performance on the test subset.  note: you need to start with the text data and convert the text to feature vectors. Please refer to https://scikitlearn.org/stable/tutorial/text_analytics/working_with_text_data.html for a tutorial on the steps needed for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c95110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "d1_data = twenty_train.data\n",
    "d1_labels = twenty_train.target\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "d1_tfidf = tfidf_vectorizer.fit_transform(d1_data)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "d1_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "d1_train_counts.shape\n",
    "\n",
    "d1_tf_transformer = TfidfTransformer(use_idf=False).fit(d1_train_counts)\n",
    "d1_train_tf = d1_tf_transformer.transform(d1_train_counts)\n",
    "d1_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51515f",
   "metadata": {},
   "source": [
    "### Dataset 2 (IMDB Reviews):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6926886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin reading files.\n",
      "Done reading negative values.\n",
      "Done reading positive values.\n",
      "File reading complete.\n"
     ]
    }
   ],
   "source": [
    "def read_imdb():\n",
    "    print(\"Begin reading files.\")\n",
    "    directory = 'data/aclImdb/train/neg'\n",
    "    data = []\n",
    "    labels = []\n",
    "    file = ''\n",
    "    for filename in os.listdir(directory):\n",
    "        f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "        file = filename, \"neg\"\n",
    "        for i in f:\n",
    "            test = True\n",
    "            while test:\n",
    "                test = False\n",
    "                k = i.find('<br /><br />')\n",
    "                if k != -1:\n",
    "                    i = i[:k] + ' ' + i[k+12:]\n",
    "                    test = True\n",
    "\n",
    "            data.append(i)\n",
    "            labels.append(0)\n",
    "\n",
    "    print(\"Done reading negative values.\")\n",
    "\n",
    "    directory = 'data/aclImdb/train/pos'\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        #print(filename)\n",
    "        f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "        file = filename, \"pos\"\n",
    "        for i in f:\n",
    "\n",
    "            test = True\n",
    "            while test:\n",
    "                test = False\n",
    "                k = i.find('<br /><br />')\n",
    "                if k != -1:\n",
    "                    i = i[:k] + ' ' + i[k+12:]\n",
    "                    test = True\n",
    "\n",
    "            data.append(i)\n",
    "            labels.append(1)\n",
    "        \n",
    "    print(\"Done reading positive values.\")\n",
    "    npdata = np.array(data)\n",
    "    nplabels = np.array(labels)\n",
    "    \n",
    "    return npdata, nplabels\n",
    "  \n",
    "d2_data, d2_labels = read_imdb()\n",
    "print(\"File reading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_vect = CountVectorizer()\n",
    "d2_train_counts = count_vect.fit_transform(d2_data)\n",
    "d2_train_counts.shape\n",
    "d2_tfidf = tfidf_vectorizer.fit_transform(d2_data)\n",
    "\n",
    "d2_tf_transformer = TfidfTransformer(use_idf=False).fit(d2_train_counts)\n",
    "d2_imdb_train_tf = d2_tf_transformer.transform(d2_train_counts)\n",
    "d2_imdb_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18c4fa",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109455e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38e107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "11314\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Fetch the 20 newsgroups dataset\n",
    "# newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Partiall dataset\n",
    "# categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "\n",
    "# Fetch the \"train\" subset of the data to be used\n",
    "# newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Vectorizing the text from the given dataset using TF-IDF to get the matrix\n",
    "data_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = data_vectorizer.fit_transform(newsgroups[\"data\"])\n",
    "\n",
    "# Defining the k-fold cross-validation with 5 folds measures to obtain the 5 groups\n",
    "kFold = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
    "\n",
    "# Defining logistic regression model with 1000 interations\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "\n",
    "print(newsgroups[\"target_names\"])\n",
    "print(len(newsgroups[\"target\"]))\n",
    "print(len(newsgroups[\"data\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503d818",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1: Newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree: 0.7832\n",
      "Precision of Decision Tree: 0.7843\n",
      "Recall of Decision Tree: 0.7832\n",
      "F1 Score of Decision Tree: 0.7830\n"
     ]
    }
   ],
   "source": [
    "#train and test data for newsgroups dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(d1_tfidf, d1_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=42, min_samples_split=10)\n",
    "\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "predicted_y = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, predicted_y)\n",
    "dt_precision = precision_score(y_test, predicted_y, average=\"weighted\")\n",
    "dt_recall = recall_score(y_test, predicted_y, average=\"weighted\")\n",
    "dt_f1_score = f1_score(y_test, predicted_y, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy of Decision Tree: {dt_accuracy:.4f}\")\n",
    "print(f\"Precision of Decision Tree: {dt_precision:.4f}\")\n",
    "print(f\"Recall of Decision Tree: {dt_recall:.4f}\")\n",
    "print(f\"F1 Score of Decision Tree: {dt_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2: IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree: 0.7376\n",
      "Precision of Decision Tree: 0.7383\n",
      "Recall of Decision Tree: 0.7376\n",
      "F1 Score of Decision Tree: 0.7375\n"
     ]
    }
   ],
   "source": [
    "#train and test for imdb dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(d2_tfidf, d2_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=42, min_samples_leaf=10, max_leaf_nodes=110, min_samples_split=20)\n",
    "\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "predicted_y = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, predicted_y)\n",
    "dt_precision = precision_score(y_test, predicted_y, average=\"weighted\")\n",
    "dt_recall = recall_score(y_test, predicted_y, average=\"weighted\")\n",
    "dt_f1_score = f1_score(y_test, predicted_y, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy of Decision Tree: {dt_accuracy:.4f}\")\n",
    "print(f\"Precision of Decision Tree: {dt_precision:.4f}\")\n",
    "print(f\"Recall of Decision Tree: {dt_recall:.4f}\")\n",
    "print(f\"F1 Score of Decision Tree: {dt_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a8ad7",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba31ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "svm_model = LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679695c",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4911e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eeb7795",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85c72f9",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7283a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,  KFold\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "model_results = {\n",
    "    \"Model\": [],\n",
    "    \"Dataset\": [],\n",
    "    \"Accuracy (Mean)\": [] \n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "svm_scores = cross_val_score(svm_model, X_tfidf, Y, cv=kf)\n",
    "svm_accuracy_mean = svm_scores.mean()\n",
    "\n",
    "model_results[\"Model\"].append(\"Support Vector Machines\")\n",
    "model_results[\"Dataset\"].append(\"20 Newsgroup\")\n",
    "model_results[\"Accuracy (Mean)\"].append(svm_accuracy_mean)\n",
    "\n",
    "# DataFrame to report the performance of SVM\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
