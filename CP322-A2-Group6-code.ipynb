{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecbf00d2",
      "metadata": {},
      "source": [
        "# <div align=\"center\">CP322-A Mini-Project 2: Machine Learning</div>\n",
        "## <div align=\"center\">Group 6</div>\n",
        "### <div align=\"center\">due on 12-Nov-2023 at 11:30 PM</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52edb19",
      "metadata": {},
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "18f51c49",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4831ebc8",
      "metadata": {},
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e10493e",
      "metadata": {},
      "source": [
        "### Dataset 1 (20 Newsgroup): \n",
        "\n",
        "Use the default train subset (subset=‘train’, and remove=([‘headers’, ‘footers’, ‘quotes’]) in  sklearn.datasets) to train the models and report the final performance on the test subset.  note: you need to start with the text data and convert the text to feature vectors. Please refer to https://scikitlearn.org/stable/tutorial/text_analytics/working_with_text_data.html for a tutorial on the steps needed for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "83c95110",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "              'comp.graphics', 'sci.med']\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset='train',\n",
        "    categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "d1_data = twenty_train.data\n",
        "d1_labels = twenty_train.target\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "d1_tfidf = tfidf_vectorizer.fit_transform(d1_data)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "d1_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "d1_train_counts.shape\n",
        "\n",
        "d1_tf_transformer = TfidfTransformer(use_idf=False).fit(d1_train_counts)\n",
        "d1_train_tf = d1_tf_transformer.transform(d1_train_counts)\n",
        "d1_train_tf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab51515f",
      "metadata": {},
      "source": [
        "### Dataset 2 (IMDB Reviews):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3f3d3e8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin reading files.\n",
            "Done reading negative values.\n",
            "Done reading positive values.\n",
            "File reading complete.\n"
          ]
        }
      ],
      "source": [
        "def read_imdb():\n",
        "    print(\"Begin reading files.\")\n",
        "    directory = 'data/aclImdb/train/neg'\n",
        "    data = []\n",
        "    labels = []\n",
        "    file = ''\n",
        "    for filename in os.listdir(directory):\n",
        "        f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
        "        file = filename, \"neg\"\n",
        "        for i in f:\n",
        "            test = True\n",
        "            while test:\n",
        "                test = False\n",
        "                k = i.find('<br /><br />')\n",
        "                if k != -1:\n",
        "                    i = i[:k] + ' ' + i[k+12:]\n",
        "                    test = True\n",
        "\n",
        "            data.append(i)\n",
        "            labels.append(0)\n",
        "\n",
        "    print(\"Done reading negative values.\")\n",
        "\n",
        "    directory = 'data/aclImdb/train/pos'\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
        "        file = filename, \"pos\"\n",
        "        for i in f:\n",
        "\n",
        "            test = True\n",
        "            while test:\n",
        "                test = False\n",
        "                k = i.find('<br /><br />')\n",
        "                if k != -1:\n",
        "                    i = i[:k] + ' ' + i[k+12:]\n",
        "                    test = True\n",
        "\n",
        "            data.append(i)\n",
        "            labels.append(1)\n",
        "        \n",
        "    print(\"Done reading positive values.\")\n",
        "    npdata = np.array(data)\n",
        "    nplabels = np.array(labels)\n",
        "    \n",
        "    return npdata, nplabels\n",
        "  \n",
        "d2_data, d2_labels = read_imdb()\n",
        "print(\"File reading complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "395e6191",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 74849)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "count_vect = CountVectorizer()\n",
        "d2_train_counts = count_vect.fit_transform(d2_data)\n",
        "d2_train_counts.shape\n",
        "d2_tfidf = tfidf_vectorizer.fit_transform(d2_data)\n",
        "\n",
        "d2_tf_transformer = TfidfTransformer(use_idf=False).fit(d2_train_counts)\n",
        "d2_imdb_train_tf = d2_tf_transformer.transform(d2_train_counts)\n",
        "d2_imdb_train_tf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b18c4fa",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5109455e",
      "metadata": {},
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f38e107a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.57      0.56        96\n",
            "           1       0.62      0.64      0.63       117\n",
            "           2       0.62      0.64      0.63       118\n",
            "           3       0.66      0.64      0.65       118\n",
            "           4       0.83      0.69      0.75       116\n",
            "           5       0.82      0.82      0.82       118\n",
            "           6       0.71      0.79      0.75       117\n",
            "           7       0.77      0.71      0.74       119\n",
            "           8       0.74      0.77      0.75       120\n",
            "           9       0.51      0.87      0.65       120\n",
            "          10       0.93      0.82      0.88       120\n",
            "          11       0.93      0.74      0.82       119\n",
            "          12       0.67      0.75      0.71       119\n",
            "          13       0.79      0.81      0.80       119\n",
            "          14       0.80      0.81      0.80       118\n",
            "          15       0.70      0.78      0.74       119\n",
            "          16       0.72      0.78      0.75       109\n",
            "          17       0.85      0.78      0.81       113\n",
            "          18       0.71      0.62      0.66        93\n",
            "          19       0.76      0.17      0.28        75\n",
            "\n",
            "    accuracy                           0.72      2263\n",
            "   macro avg       0.74      0.71      0.71      2263\n",
            "weighted avg       0.74      0.72      0.72      2263\n",
            "\n",
            "Accuracy: 0.71\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.53      0.55        96\n",
            "           1       0.68      0.71      0.69       116\n",
            "           2       0.69      0.74      0.71       118\n",
            "           3       0.71      0.64      0.67       118\n",
            "           4       0.80      0.61      0.69       116\n",
            "           5       0.76      0.78      0.77       119\n",
            "           6       0.73      0.73      0.73       117\n",
            "           7       0.68      0.70      0.69       119\n",
            "           8       0.71      0.68      0.69       120\n",
            "           9       0.50      0.82      0.62       119\n",
            "          10       0.85      0.83      0.84       120\n",
            "          11       0.88      0.77      0.83       119\n",
            "          12       0.62      0.64      0.63       118\n",
            "          13       0.81      0.82      0.82       119\n",
            "          14       0.79      0.72      0.75       119\n",
            "          15       0.64      0.81      0.72       120\n",
            "          16       0.75      0.78      0.76       109\n",
            "          17       0.78      0.74      0.76       113\n",
            "          18       0.65      0.69      0.67        93\n",
            "          19       0.78      0.19      0.30        75\n",
            "\n",
            "    accuracy                           0.71      2263\n",
            "   macro avg       0.72      0.70      0.69      2263\n",
            "weighted avg       0.72      0.71      0.70      2263\n",
            "\n",
            "Accuracy: 0.70\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53        96\n",
            "           1       0.61      0.66      0.63       117\n",
            "           2       0.65      0.67      0.66       118\n",
            "           3       0.65      0.61      0.63       118\n",
            "           4       0.74      0.67      0.70       115\n",
            "           5       0.79      0.78      0.78       119\n",
            "           6       0.68      0.74      0.70       117\n",
            "           7       0.70      0.62      0.66       119\n",
            "           8       0.68      0.79      0.73       120\n",
            "           9       0.51      0.87      0.65       119\n",
            "          10       0.87      0.84      0.86       120\n",
            "          11       0.84      0.81      0.82       119\n",
            "          12       0.66      0.61      0.63       118\n",
            "          13       0.84      0.70      0.76       119\n",
            "          14       0.75      0.81      0.78       119\n",
            "          15       0.67      0.74      0.70       120\n",
            "          16       0.72      0.70      0.71       109\n",
            "          17       0.92      0.79      0.85       113\n",
            "          18       0.66      0.65      0.65        93\n",
            "          19       0.63      0.16      0.26        75\n",
            "\n",
            "    accuracy                           0.70      2263\n",
            "   macro avg       0.70      0.69      0.69      2263\n",
            "weighted avg       0.71      0.70      0.70      2263\n",
            "\n",
            "Accuracy: 0.71\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62        96\n",
            "           1       0.70      0.65      0.67       117\n",
            "           2       0.74      0.66      0.70       118\n",
            "           3       0.68      0.69      0.68       118\n",
            "           4       0.75      0.65      0.70       115\n",
            "           5       0.78      0.76      0.77       119\n",
            "           6       0.68      0.81      0.74       117\n",
            "           7       0.72      0.64      0.68       119\n",
            "           8       0.64      0.65      0.64       119\n",
            "           9       0.52      0.87      0.65       119\n",
            "          10       0.86      0.85      0.86       120\n",
            "          11       0.94      0.71      0.81       119\n",
            "          12       0.57      0.73      0.64       118\n",
            "          13       0.75      0.79      0.77       119\n",
            "          14       0.76      0.70      0.73       119\n",
            "          15       0.63      0.80      0.71       120\n",
            "          16       0.76      0.81      0.78       109\n",
            "          17       0.85      0.73      0.78       113\n",
            "          18       0.77      0.63      0.69        93\n",
            "          19       0.62      0.17      0.27        76\n",
            "\n",
            "    accuracy                           0.71      2263\n",
            "   macro avg       0.72      0.70      0.69      2263\n",
            "weighted avg       0.72      0.71      0.70      2263\n",
            "\n",
            "Accuracy: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.59      0.59        96\n",
            "           1       0.70      0.66      0.68       117\n",
            "           2       0.70      0.68      0.69       119\n",
            "           3       0.65      0.66      0.66       118\n",
            "           4       0.75      0.77      0.76       116\n",
            "           5       0.80      0.77      0.78       118\n",
            "           6       0.75      0.79      0.77       117\n",
            "           7       0.68      0.70      0.69       118\n",
            "           8       0.70      0.75      0.72       119\n",
            "           9       0.53      0.86      0.65       120\n",
            "          10       0.90      0.85      0.88       120\n",
            "          11       0.83      0.71      0.77       119\n",
            "          12       0.60      0.60      0.60       118\n",
            "          13       0.80      0.86      0.82       118\n",
            "          14       0.75      0.78      0.77       118\n",
            "          15       0.70      0.77      0.73       120\n",
            "          16       0.79      0.70      0.74       110\n",
            "          17       0.85      0.83      0.84       112\n",
            "          18       0.74      0.60      0.66        93\n",
            "          19       0.65      0.20      0.30        76\n",
            "\n",
            "    accuracy                           0.72      2262\n",
            "   macro avg       0.72      0.71      0.71      2262\n",
            "weighted avg       0.72      0.72      0.71      2262\n",
            "\n",
            "\n",
            "Average Metrics Across the 5 K-Folds:\n",
            "Average Accuracy of the dataset is: 0.71\n",
            "Average Precision of the dataset is: 0.72\n",
            "Average Recall of the dataset is: 0.70\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Fetch the 20 newsgroups dataset\n",
        "# newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Partiall dataset\n",
        "# categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
        "\n",
        "\n",
        "# Fetch the \"train\" subset of the data to be used\n",
        "# newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Vectorizing the text from the given dataset using TF-IDF to get the matrix\n",
        "data_vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_tfidf = data_vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "# Defining the k-fold cross-validation with 5 folds measures to obtain the 5 groups\n",
        "kFold = StratifiedKFold(n_splits=5,shuffle=True, random_state=42)\n",
        "\n",
        "# Defining logistic regression model with 1000 interations\n",
        "logistic_regression = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Defining place holder lists for the metrics for each of the resulting folds\n",
        "accuracies_array = []\n",
        "precisions_array = []\n",
        "recalls_array = []\n",
        "# Implementing k-fold cross-validation using the test and train data\n",
        "for train_position, test_position in kFold.split(X_tfidf, newsgroups.target):\n",
        "    X_trainData= X_tfidf[train_position]\n",
        "    X_testData = X_tfidf[test_position]\n",
        "    y_trainData = newsgroups.target[train_position]\n",
        "    y_testData= newsgroups.target[test_position]\n",
        "\n",
        "    \n",
        "    #Using the training portion of data to train it for our Logistic regression model\n",
        "    logistic_regression.fit(X_trainData, y_trainData)\n",
        "\n",
        "    # Defining our predicts on the test data of the dataset\n",
        "    y_predictData = logistic_regression.predict(X_testData)\n",
        "\n",
        "    # Analysing the models using each of the k-folds\n",
        "    accuracy = accuracy_score(y_testData, y_predictData)\n",
        "    classification_report_dict = classification_report(y_testData, y_predictData, output_dict=True)\n",
        "    \n",
        "    \n",
        "    # Adding the metrictics int the defined lists to be used for final average\n",
        "    accuracies_array.append(accuracy)\n",
        "    precisions_array.append(classification_report_dict['macro avg']['precision'])\n",
        "    recalls_array.append(classification_report_dict['macro avg']['recall'])\n",
        "\n",
        "    # Dispaying the results of the metrics of the 5 folds\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "    print(classification_report(y_testData, y_predictData))\n",
        "\n",
        "# Aggregate and displays the average rsults of the metrics using all the k-folds.\n",
        "avg_accuracy = sum(accuracies_array) / len(accuracies_array)\n",
        "avg_precision = sum(precisions_array) / len(precisions_array)\n",
        "avg_recall = sum(recalls_array) / len(recalls_array)\n",
        "\n",
        "# Final display of the results\n",
        "print(\"\\nAverage Metrics Across the 5 K-Folds:\")\n",
        "print(f'Average Accuracy of the dataset is: {avg_accuracy:.2f}')\n",
        "print(f'Average Precision of the dataset is: {avg_precision:.2f}')\n",
        "print(f'Average Recall of the dataset is: {avg_recall:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f503d818",
      "metadata": {},
      "source": [
        "### Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806cd223",
      "metadata": {},
      "source": [
        "##### Dataset 1 (20 Newsgroup):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b0190c6b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Tree: 0.7832\n",
            "Precision of Decision Tree: 0.7843\n",
            "Recall of Decision Tree: 0.7832\n",
            "F1 Score of Decision Tree: 0.7830\n"
          ]
        }
      ],
      "source": [
        "#train and test data for newsgroups dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(d1_tfidf, d1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=42, min_samples_split=10)\n",
        "\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "predicted_y = decision_tree_classifier.predict(X_test)\n",
        "\n",
        "dt_accuracy = metrics.accuracy_score(y_test, predicted_y)\n",
        "dt_precision = metrics.precision_score(y_test, predicted_y, average=\"weighted\")\n",
        "dt_recall = metrics.recall_score(y_test, predicted_y, average=\"weighted\")\n",
        "dt_f1_score = metrics.f1_score(y_test, predicted_y, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy of Decision Tree: {dt_accuracy:.4f}\")\n",
        "print(f\"Precision of Decision Tree: {dt_precision:.4f}\")\n",
        "print(f\"Recall of Decision Tree: {dt_recall:.4f}\")\n",
        "print(f\"F1 Score of Decision Tree: {dt_f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5135073",
      "metadata": {},
      "source": [
        "##### Dataset 2 (IMDB Reviews):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "19716ebb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Tree: 0.7444\n",
            "Precision of Decision Tree: 0.7448\n",
            "Recall of Decision Tree: 0.7444\n",
            "F1 Score of Decision Tree: 0.7443\n"
          ]
        }
      ],
      "source": [
        "#train and test for imdb dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(d2_tfidf, d2_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=42, min_samples_leaf=10, max_leaf_nodes=110, min_samples_split=20)\n",
        "\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "predicted_y = decision_tree_classifier.predict(X_test)\n",
        "\n",
        "dt_accuracy = metrics.accuracy_score(y_test, predicted_y)\n",
        "dt_precision = metrics.precision_score(y_test, predicted_y, average=\"weighted\")\n",
        "dt_recall = metrics.recall_score(y_test, predicted_y, average=\"weighted\")\n",
        "dt_f1_score = metrics.f1_score(y_test, predicted_y, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy of Decision Tree: {dt_accuracy:.4f}\")\n",
        "print(f\"Precision of Decision Tree: {dt_precision:.4f}\")\n",
        "print(f\"Recall of Decision Tree: {dt_recall:.4f}\")\n",
        "print(f\"F1 Score of Decision Tree: {dt_f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a89a8ad7",
      "metadata": {},
      "source": [
        "### Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a13ea20f",
      "metadata": {},
      "source": [
        "##### Dataset 1 (20 Newsgroup):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8e102688",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9996\n",
            "Precision: 0.9996\n",
            "Recall: 0.9996\n",
            "F1 Score: 0.9996\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score,  KFold \n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "svm_model = LinearSVC(dual=False)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "model_results = {\n",
        "    \"Dataset\": [],\n",
        "    \"Accuracy Score\": [],\n",
        "    \"Precision Score\": [],\n",
        "    \"Recall Score\": [],\n",
        "    \"F1 Score\": []\n",
        "}\n",
        "\n",
        "svm_scores_20newsgroup = cross_val_score(svm_model, d1_tfidf, d1_labels, cv=kf)\n",
        "Y_pred_20newsgroup = svm_model.fit(d1_tfidf, d1_labels).predict(d1_tfidf)\n",
        "\n",
        "svm_accuracy = metrics.accuracy_score(Y_pred_20newsgroup, d1_labels)\n",
        "svm_precision = (metrics.precision_score(Y_pred_20newsgroup,d1_labels, average='weighted'))\n",
        "svm_recall = (recall_score(Y_pred_20newsgroup, d1_labels, average='weighted'))\n",
        "svm_f1_score = (f1_score(Y_pred_20newsgroup, d1_labels, average='weighted'))\n",
        "\n",
        "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
        "print(f\"Precision: {svm_precision:.4f}\")\n",
        "print(f\"Recall: {svm_recall:.4f}\")\n",
        "print(f\"F1 Score: {svm_f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc72bc23",
      "metadata": {},
      "source": [
        "##### Dataset 2 (IMDB Reviews):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "697a0a65",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9901\n",
            "Precision: 0.9901\n",
            "Recall: 0.9901\n",
            "F1 Score: 0.9901\n"
          ]
        }
      ],
      "source": [
        "Y_pred_imdb = svm_model.fit(d2_tfidf, d2_labels).predict(d2_tfidf)\n",
        "\n",
        "svm_accuracy = metrics.accuracy_score(d2_labels,Y_pred_imdb)\n",
        "svm_precision = (metrics.precision_score(d2_labels,Y_pred_imdb, average='weighted'))\n",
        "svm_recall = (recall_score(d2_labels, Y_pred_imdb,average='weighted'))\n",
        "svm_f1_score = (f1_score(d2_labels, Y_pred_imdb, average='weighted'))\n",
        "\n",
        "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
        "print(f\"Precision: {svm_precision:.4f}\")\n",
        "print(f\"Recall: {svm_recall:.4f}\")\n",
        "print(f\"F1 Score: {svm_f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b679695c",
      "metadata": {},
      "source": [
        "### Ada Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b16d26",
      "metadata": {},
      "source": [
        "##### Dataset 1 (20 Newsgroup):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bd4911e7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Testing IMDb Dataset\n",
            "========================================\n",
            "Accuracy with number of estimators 3 is: 0.5287610619469026\n",
            "Accuracy with number of estimators 10 is: 0.7101769911504425\n",
            "Accuracy with number of estimators 50 is: 0.754424778761062\n",
            "Accuracy with number of estimators 100 is: 0.8097345132743363\n",
            "Accuracy with number of estimators 300 is: 0.8230088495575221\n",
            "Accuracy with number of estimators 500 is: 0.834070796460177\n",
            "Accuracy with learning rate: 0.1 is: 0.8539823008849557\n",
            "Accuracy with learning rate: 0.5 is: 0.8230088495575221\n",
            "Accuracy with learning rate: 0.8 is: 0.7566371681415929\n",
            "Accuracy with learning rate: 1 is: 0.7765486725663717\n",
            "Accuracy with learning rate: 1.5 is: 0.8097345132743363\n",
            "Accuracy with learning rate: 2 is: 0.6902654867256637\n",
            "Accuracy with learning rate: 3 is: 0.4358407079646018\n",
            "Accuracy: 0.8584070796460177\n",
            "Precision: 0.8693052375994887\n",
            "Recall: 0.8584070796460177\n",
            "F1 Score: 0.8580173961731085\n"
          ]
        }
      ],
      "source": [
        "processed_train_data, processed_test_data, y_train, y_test = train_test_split(d1_tfidf, d1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "for estimators in [3,10,50,100,300,500]:\n",
        "    boost = AdaBoostClassifier(n_estimators = estimators, learning_rate = 0.5)\n",
        "    model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "    y_pred = model.predict(processed_test_data)\n",
        "\n",
        "    print(\"Accuracy with number of estimators\", estimators, \"is:\", metrics.accuracy_score(y_pred, y_test))\n",
        "\n",
        "for alpha in [0.1,0.5,0.8,1,1.5,2,3]: #note that from 2 onwards produces the exact same accuracy\n",
        "    boost = AdaBoostClassifier(n_estimators = 300, learning_rate = alpha)\n",
        "    model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "    y_pred = model.predict(processed_test_data)\n",
        "\n",
        "    print(\"Accuracy with learning rate:\", alpha, \"is:\", metrics.accuracy_score(y_pred, y_test))\n",
        "\n",
        "boost = AdaBoostClassifier(n_estimators = 1000, learning_rate = 0.5)\n",
        "model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "y_pred = model.predict(processed_test_data)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_pred, y_test))\n",
        "print(\"Precision:\", metrics.precision_score(y_pred, y_test,average='weighted'))\n",
        "print(\"Recall:\", metrics.recall_score(y_pred, y_test,average='weighted'))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_pred, y_test,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eaa2a67",
      "metadata": {},
      "source": [
        "##### Dataset 2 (IMDB Reviews):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "38a4509c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with number of estimators 3 is: 0.655\n",
            "Accuracy with number of estimators 10 is: 0.7282\n",
            "Accuracy with number of estimators 50 is: 0.8066\n",
            "Accuracy with number of estimators 100 is: 0.8318\n",
            "Accuracy with number of estimators 300 is: 0.8636\n",
            "Accuracy with number of estimators 500 is: 0.8686\n",
            "Accuracy with learning rate: 0.1 is: 0.8216\n",
            "Accuracy with learning rate: 0.5 is: 0.8636\n",
            "Accuracy with learning rate: 0.8 is: 0.8576\n",
            "Accuracy with learning rate: 1 is: 0.8524\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1.5\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]: \u001b[38;5;66;03m#note that from 2 onwards produces the exact same accuracy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     boost \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m alpha)\n\u001b[1;32m---> 13\u001b[0m     model \u001b[38;5;241m=\u001b[39m boost\u001b[38;5;241m.\u001b[39mfit(processed_train_data, y_train)\n\u001b[0;32m     15\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(processed_test_data)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy with learning rate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_pred, y_test))\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:171\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    168\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[0;32m    172\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    173\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:579\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:588\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    586\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 588\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    590\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "processed_train_data, processed_test_data, y_train, y_test = train_test_split(d2_tfidf, d2_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "for estimators in [3,10,50,100,300,500]:\n",
        "    boost = AdaBoostClassifier(n_estimators = estimators, learning_rate = 0.5)\n",
        "    model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "    y_pred = model.predict(processed_test_data)\n",
        "\n",
        "    print(\"Accuracy with number of estimators\", estimators, \"is:\", metrics.accuracy_score(y_pred, y_test))\n",
        "\n",
        "for alpha in [0.1,0.5,0.8,1,1.5,2,3]: #note that from 2 onwards produces the exact same accuracy\n",
        "    boost = AdaBoostClassifier(n_estimators = 300, learning_rate = alpha)\n",
        "    model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "    y_pred = model.predict(processed_test_data)\n",
        "\n",
        "    print(\"Accuracy with learning rate:\", alpha, \"is:\", metrics.accuracy_score(y_pred, y_test))\n",
        "\n",
        "boost = AdaBoostClassifier(n_estimators = 300, learning_rate = 0.5)\n",
        "model = boost.fit(processed_train_data, y_train)\n",
        "\n",
        "y_pred = model.predict(processed_test_data)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_pred, y_test))\n",
        "print(\"Precision:\", metrics.precision_score(y_pred, y_test,average='weighted'))\n",
        "print(\"Recall:\", metrics.recall_score(y_pred, y_test,average='weighted'))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_pred, y_test,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9b1b20f",
      "metadata": {},
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e498d99f",
      "metadata": {},
      "source": [
        "##### Dataset 1 (20 Newsgroup):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f5234eaa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8606\n",
            "Precision: 0.8803\n",
            "Recall: 0.8606\n",
            "F1 Score: 0.8618\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(d1_tfidf, d1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "rf_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "rf_precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
        "rf_recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
        "rf_f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1 Score: {rf_f1_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8faf0ef3",
      "metadata": {},
      "source": [
        "##### Dataset 2 (IMDB Reviews):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e1472a5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8372\n",
            "Precision: 0.8372\n",
            "Recall: 0.8372\n",
            "F1 Score: 0.8372\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(d2_tfidf, d2_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "rf_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "rf_precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
        "rf_recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
        "rf_f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_precision:.4f}\")\n",
        "print(f\"Recall: {rf_recall:.4f}\")\n",
        "print(f\"F1 Score: {rf_f1_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85c72f9",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a7283a3f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\twbm\\AppData\\Local\\Temp\\ipykernel_11924\\1104062206.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "C:\\Users\\twbm\\AppData\\Local\\Temp\\ipykernel_11924\\1104062206.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "C:\\Users\\twbm\\AppData\\Local\\Temp\\ipykernel_11924\\1104062206.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n",
            "C:\\Users\\twbm\\AppData\\Local\\Temp\\ipykernel_11924\\1104062206.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Model  Accuracy  Precision    Recall  F1 Score\n",
            "0        Random Forest  0.880811   0.895755  0.880811  0.881001\n",
            "1             AdaBoost  0.739916   0.755450  0.739916  0.740215\n",
            "2                  SVM  0.963663   0.964693  0.963663  0.963687\n",
            "3        Decision Tree  0.780245   0.781392  0.780245  0.780037\n",
            "4  Logistic Regression  0.945496   0.948900  0.945496  0.945737\n",
            "\n",
            "Best Models:\n",
            "Accuracy: SVM\n",
            "Precision: SVM\n",
            "Recall: SVM\n",
            "F1 Score: SVM\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\twbm\\AppData\\Local\\Temp\\ipykernel_11924\\1104062206.py:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_df = results_df.append({\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import pandas as pd\n",
        "\n",
        "# Define models with their hyperparameters\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    'SVM': SVC(kernel='linear', probability=True, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Create a DataFrame to store performance metrics\n",
        "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "# Model validation pipeline\n",
        "for model_name, model in models.items():\n",
        "    accuracy_scores = cross_val_score(model, X_tfidf, Y, cv=kf, scoring='accuracy')\n",
        "    precision_scores = cross_val_score(model, X_tfidf, Y, cv=kf, scoring='precision_weighted')\n",
        "    recall_scores = cross_val_score(model, X_tfidf, Y, cv=kf, scoring='recall_weighted')\n",
        "    f1_scores = cross_val_score(model, X_tfidf, Y, cv=kf, scoring='f1_weighted')\n",
        "\n",
        "    results_df = results_df.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_scores.mean(),\n",
        "        'Precision': precision_scores.mean(),\n",
        "        'Recall': recall_scores.mean(),\n",
        "        'F1 Score': f1_scores.mean()\n",
        "    }, ignore_index=True)\n",
        "\n",
        "# Print the results table\n",
        "print(results_df)\n",
        "\n",
        "# Identify the best model for each metric\n",
        "best_accuracy_model = results_df.loc[results_df['Accuracy'].idxmax()]['Model']\n",
        "best_precision_model = results_df.loc[results_df['Precision'].idxmax()]['Model']\n",
        "best_recall_model = results_df.loc[results_df['Recall'].idxmax()]['Model']\n",
        "best_f1_model = results_df.loc[results_df['F1 Score'].idxmax()]['Model']\n",
        "\n",
        "print(\"\\nBest Models:\")\n",
        "print(f\"Accuracy: {best_accuracy_model}\")\n",
        "print(f\"Precision: {best_precision_model}\")\n",
        "print(f\"Recall: {best_recall_model}\")\n",
        "print(f\"F1 Score: {best_f1_model}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f7498ec",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
