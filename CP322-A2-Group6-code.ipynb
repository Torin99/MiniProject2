{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbf00d2",
   "metadata": {},
   "source": [
    "# <div align=\"center\">CP322-A Mini-Project 2: Machine Learning</div>\n",
    "## <div align=\"center\">Group 6</div>\n",
    "### <div align=\"center\">due on 12-Nov-2023 at 11:30 PM</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52edb19",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f51c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831ebc8",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10493e",
   "metadata": {},
   "source": [
    "### Dataset 1 (20 Newsgroup): \n",
    "\n",
    "Use the default train subset (subset=‘train’, and remove=([‘headers’, ‘footers’, ‘quotes’]) in  sklearn.datasets) to train the models and report the final performance on the test subset.  note: you need to start with the text data and convert the text to feature vectors. Please refer to https://scikitlearn.org/stable/tutorial/text_analytics/working_with_text_data.html for a tutorial on the steps needed for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c95110",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "X = twenty_train.data\n",
    "Y = twenty_train.target\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51515f",
   "metadata": {},
   "source": [
    "### Dataset 2 (IMDB Reviews):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6926886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def read_train_imdb():\n",
    "    directory = 'data/train/neg'\n",
    "    data = []\n",
    "    labels = []\n",
    "    file = ''\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"neg\"\n",
    "            for i in f:\n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                    \n",
    "                data.append(i)\n",
    "                labels.append(0)\n",
    "                     \n",
    "        directory = 'data/train/pos'\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"pos\"\n",
    "            for i in f:\n",
    "             \n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                     \n",
    "                data.append(i)\n",
    "                labels.append(1)\n",
    "                \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Error found in file:\", file)\n",
    "        \n",
    "    npdata = np.array(data)\n",
    "    nplabels = np.array(labels)\n",
    "    \n",
    "    return npdata, nplabels\n",
    "  \n",
    "train_data, train_labels = read_train_imdb()\n",
    "print(\"File reading complete.\")\n",
    "\n",
    "def read_test_imdb():\n",
    "    directory = 'data/test/neg'\n",
    "    data = []\n",
    "    labels = []\n",
    "    file = ''\n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"neg\"\n",
    "            for i in f:\n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                    \n",
    "                data.append(i)\n",
    "                labels.append(0)\n",
    "                \n",
    "        \n",
    "        directory = 'data/test/pos'\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            f = open(os.path.join(directory, filename), encoding=\"utf-8\")\n",
    "            file = filename, \"pos\"\n",
    "            for i in f:\n",
    "             \n",
    "                test = True\n",
    "                while test:\n",
    "                    test = False\n",
    "                    k = i.find('<br /><br />')\n",
    "                    if k != -1:\n",
    "                        i = i[:k] + ' ' + i[k+12:]\n",
    "                        test = True\n",
    "                     \n",
    "                data.append(i)\n",
    "                labels.append(1)\n",
    "                \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Error found in file:\", file)\n",
    "    \n",
    "    npdata = np.array(data)\n",
    "    nplabels = np.array(labels)\n",
    "    \n",
    "    return npdata, nplabels\n",
    "  \n",
    "test_data, test_labels = read_test_imdb()\n",
    "print(\"File reading complete.\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = 'word', max_features = 5000)\n",
    "vectorizer.fit(train_data)\n",
    "processed_train_data =  vectorizer.transform(train_data)\n",
    "processed_test_data =  vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18c4fa",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5109455e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e107a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f503d818",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0190c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a89a8ad7",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e102688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score,  KFold \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "model_results = {\n",
    "    \"Dataset\": [],\n",
    "    \"Accuracy Score\": [],\n",
    "    \"Precision Score\": [],\n",
    "    \"Recall Score\": [],\n",
    "    \"F1 Score\": []\n",
    "}\n",
    "\n",
    "svm_scores_20newsgroup = cross_val_score(svm_model, X_tfidf, Y, cv=kf)\n",
    "Y_pred_20newsgroup = svm_model.fit(X_tfidf, Y).predict(X_tfidf)\n",
    "\n",
    "model_results[\"Dataset\"].append(\"20 Newsgroup\")\n",
    "model_results[\"Accuracy Score\"].append(accuracy_score(Y, Y_pred_20newsgroup))\n",
    "model_results[\"Precision Score\"].append(precision_score(Y, Y_pred_20newsgroup, average='weighted'))\n",
    "model_results[\"Recall Score\"].append(recall_score(Y, Y_pred_20newsgroup, average='weighted'))\n",
    "model_results[\"F1 Score\"].append(f1_score(Y, Y_pred_20newsgroup, average='weighted'))\n",
    "\n",
    "svm_scores_imdb = cross_val_score(svm_model, processed_train_data, train_labels, cv=kf)\n",
    "Y_pred_imdb = svm_model.fit(processed_train_data, train_labels).predict(processed_train_data)\n",
    "\n",
    "model_results[\"Dataset\"].append(\"IMDB Reviews\")\n",
    "model_results[\"Accuracy Score\"].append(accuracy_score(train_labels, Y_pred_imdb))\n",
    "model_results[\"Precision Score\"].append(precision_score(train_labels, Y_pred_imdb, average='weighted'))\n",
    "model_results[\"Recall Score\"].append(recall_score(train_labels, Y_pred_imdb, average='weighted'))\n",
    "model_results[\"F1 Score\"].append(f1_score(train_labels, Y_pred_imdb, average='weighted'))\n",
    "\n",
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679695c",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4911e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eeb7795",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85c72f9",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7283a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
